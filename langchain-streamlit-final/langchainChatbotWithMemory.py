# streamlitê³¼ pyngrok openai ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜
# !pip install streamlit -q
# !pip install pyngrok -q
# !pip install openai==0.28.1 -q


# openai, streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import openai
import streamlit as st
import os

from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage, Document
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA, ConversationalRetrievalChain

from langchain.memory import ConversationBufferMemory


# sidebarì— OpenAI API í‚¤ ì•”í˜¸ë¡œ ì…ë ¥ ë°›ê¸°
# API í‚¤ ë°œê¸‰ ì‚¬ì´íŠ¸ ê³µì§€í•˜ê¸°- https://platform.openai.com/account/api-keys
# with st.sidebar:
#     openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
#     "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"


openai_api_key = os.getenv("OPENAI_API_KEY")
k = 3

# ğŸ’¬ ì•± ì œëª©ê³¼ ğŸš€ ì„¤ëª…
st.title("ğŸ’¬ ì±—ë´‡")
st.caption("ğŸš€ OpenAIë¥¼ ì´ìš©í•œ ìŠ¤íŠ¸ë¦¼ë¦¿ ì±—ë´‡")

# ì´ˆê¸° ë©”ì‹œì§€ ì„¤ì •
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}]
    

    db_path = '../db3'
    embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
    st.session_state["database"] = Chroma(persist_directory= db_path, embedding_function = embeddings )
    # database = Chroma(persist_directory= db_path, embedding_function = embeddings )  
    
    retriever =  st.session_state["database"].as_retriever(search_kwargs={"k": k})
    chat = ChatOpenAI(model="gpt-3.5-turbo")
    st.session_state["memory"] = ConversationBufferMemory(memory_key="chat_history", input_key="question",
                                output_key="answer", return_messages=True)
    st.session_state["qa"] = ConversationalRetrievalChain.from_llm(llm=chat, retriever=retriever, memory=st.session_state["memory"],    
                                           return_source_documents=True,  output_key="answer")

# ëª¨ë“  ëŒ€í™” ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œ
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

  


# ëŒ€í™” ë©”ëª¨ë¦¬ ìƒì„±
# memory = ConversationBufferMemory(memory_key="chat_history", input_key="question",
#                                 output_key="answer", return_messages=True)
# qa = ConversationalRetrievalChain.from_llm(llm=chat, retriever=retriever, memory=memory,    
#                                            return_source_documents=True,  output_key="answer")

# count = 0
# count  += 1
# print("count", count)


# ì‚¬ìš©ì ì±„íŒ… ì…ë ¥ í™•ì¸
if prompt := st.chat_input():

    # API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ì„ ê²½ìš°, ë©”ì‹œì§€ë¥¼ í‘œì‹œí•˜ê³  í”„ë¡œê·¸ë¨ì„ ì¤‘ë‹¨
    if not openai_api_key:
        st.info("OpenAI API keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    # OpenAI API í‚¤ ì„¤ì •
    openai.api_key = openai_api_key

    # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # # OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
    # response = openai.ChatCompletion.create(
    #     model="gpt-3.5-turbo",
    #     messages=st.session_state.messages
    # )

    # ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œ
    # msg = response.choices[0].message["content"]

    
    # ConversationalRetrievalQA ì²´ì¸ ìƒì„±
    
    
    # qa = get_conversation_chain_memory(memory,k)

    result = st.session_state["database"].similarity_search_with_score(prompt, k = k) #â† ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´
    # sim1 = round(result[0][1], 5)
    # sim2 = round(result[1][1], 5)
    # sim3 = round(result[2][1], 5)

    
    result = st.session_state["qa"]({"question": prompt})
    msg = result["answer"]

    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)

    # í˜„ì¬ ë‹´ê²¨ ìˆëŠ” ë©”ëª¨ë¦¬ ë‚´ìš© ì „ì²´ í™•ì¸
    history = st.session_state["memory"].load_memory_variables({})
    print(history)
